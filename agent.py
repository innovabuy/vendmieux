"""
VendMieux ‚Äî Agent vocal temps r√©el
Simulateur de prospect IA pour formation commerciale

Architecture :
  Micro du commercial ‚Üí Deepgram STT ‚Üí Claude LLM (persona prospect) ‚Üí ElevenLabs TTS ‚Üí Haut-parleur

L'agent joue le r√¥le d'un prospect fran√ßais r√©aliste,
g√©n√©r√© dynamiquement √† partir d'un sc√©nario FORCE 3D.
"""

import asyncio
import json
import os
import random
import time
import logging
import threading
from collections.abc import AsyncIterable
from pathlib import Path
from dotenv import load_dotenv
import httpx

from livekit import agents, rtc
from livekit.agents import (
    Agent,
    AgentSession,
    AgentServer,
    JobContext,
    JobProcess,
    RunContext,
    function_tool,
)
from livekit.agents.voice.agent import ModelSettings
from livekit.plugins import deepgram, silero, anthropic
from livekit.plugins import google as google_tts

from tts_utils import normalize_tts_stream


load_dotenv()
logger = logging.getLogger("vendmieux")
logger.setLevel(logging.INFO)

# --- R√©pertoire des sc√©narios ---
SCENARIOS_DIR = Path(__file__).parent / "scenarios"


# --- Cache sc√©narios en m√©moire (√©vite re-conversion √† chaque session) ---
_scenarios_cache: dict[str, dict] = {}
_scenarios_db_loaded = False

# Historique conversation par room pour r√©silience reconnexion
_room_history: dict[str, dict] = {}
_room_history_lock = threading.Lock()
_ROOM_HISTORY_TTL = 900  # 15 min


def _save_room_history(room_name: str, session: AgentSession):
    """Sauvegarde l'historique de conversation pour reconnexion."""
    with _room_history_lock:
        _room_history[room_name] = {
            "history": session.history.to_dict(),
            "ts": time.time(),
        }
        # Purger les entr√©es p√©rim√©es
        cutoff = time.time() - _ROOM_HISTORY_TTL
        stale = [k for k, v in _room_history.items() if v["ts"] < cutoff]
        for k in stale:
            del _room_history[k]


def _pop_room_history(room_name: str) -> dict | None:
    """R√©cup√®re et supprime l'historique stock√©. None si absent/expir√©."""
    with _room_history_lock:
        entry = _room_history.pop(room_name, None)
        if entry and (time.time() - entry["ts"]) < _ROOM_HISTORY_TTL:
            return entry["history"]
        return None


def _ensure_scenarios_db():
    """Charge la base de sc√©narios en cache une seule fois."""
    global _scenarios_db_loaded
    if not _scenarios_db_loaded:
        from scenarios_database import load_scenarios_database
        _scenarios_cache.update(load_scenarios_database())
        _scenarios_db_loaded = True
        logger.info(f"üì¶ Cache sc√©narios initialis√© : {len(_scenarios_cache)} sc√©narios")


def load_scenario(scenario_id: str) -> dict | None:
    """Charge un sc√©nario depuis le cache m√©moire ou le dossier scenarios/"""
    _ensure_scenarios_db()
    if scenario_id in _scenarios_cache:
        return _scenarios_cache[scenario_id]
    # Fallback sur les fichiers JSON (sc√©narios g√©n√©r√©s par l'utilisateur)
    filepath = SCENARIOS_DIR / f"{scenario_id}.json"
    if filepath.exists():
        with open(filepath, "r", encoding="utf-8") as f:
            scenario = json.load(f)
        _scenarios_cache[scenario_id] = scenario  # Cache pour prochaine utilisation
        return scenario
    return None


class VendMieuxProspect(Agent):
    """Agent qui joue le r√¥le d'un prospect pour VendMieux"""

    def __init__(self, system_prompt: str, scenario_name: str = ""):
        super().__init__(
            instructions=system_prompt,
        )
        self.scenario_name = scenario_name
        logger.info(f"üé≠ Prospect VendMieux initialis√© : {scenario_name}")

    async def tts_node(
        self,
        text: AsyncIterable[str],
        model_settings: ModelSettings,
    ) -> AsyncIterable[rtc.AudioFrame]:
        """Override pour normaliser le texte avant envoi au TTS Google."""
        normalized_text = normalize_tts_stream(text)
        async for frame in super().tts_node(normalized_text, model_settings):
            yield frame


# --- Sc√©nario par d√©faut (hardcod√© pour le premier test) ---
DEFAULT_SCENARIO = {
    "extraction": {
        "contexte": {"type_vente": "prospection_telephonique"},
        "objectif_formation": "Passer le barrage et cr√©er l'urgence",
    },
    "persona": {
        "identite": {
            "prenom": "Olivier",
            "nom": "Bertrand",
            "age": 52,
            "poste": "Directeur G√©n√©ral",
            "entreprise": {
                "nom": "M√©capress Rh√¥ne-Alpes",
                "secteur": "Industrie m√©canique",
                "taille": "85 salari√©s",
                "ca_approximatif": "12M‚Ç¨",
            },
        },
        "psychologie": {
            "traits_dominants": ["pragmatique", "direct", "m√©fiant envers les commerciaux"],
            "motivations_profondes": [
                "R√©duire les co√ªts de maintenance",
                "Moderniser sans prendre de risque",
            ],
            "peurs_freins": [
                "Perdre du temps avec un vendeur",
                "S'engager sur une techno non √©prouv√©e",
            ],
            "rapport_aux_commerciaux": "Les tol√®re s'ils sont concrets et rapides, d√©teste le blabla commercial",
            "style_communication": "directif",
        },
        "comportement_en_rdv": {
            "ton_initial": "Neutre-froid, pas hostile mais pas accueillant",
            "signaux_interet": [
                "pose des questions techniques",
                "demande des r√©f√©rences dans son secteur",
                "√©voque ses propres probl√®mes de maintenance",
            ],
            "signaux_rejet": [
                "soupire",
                "r√©pond par monosyllabes",
                "dit 'bon √©coutez...'",
            ],
            "tics_langage": [
                "Bon...",
                "Concr√®tement ?",
                "Et donc ?",
                "√âcoutez...",
            ],
            "debit_parole": "rapide",
            "tolerance_monologue_vendeur": "15 secondes",
        },
        "contexte_actuel": {
            "situation_entreprise": "PME industrielle en croissance, 2 pannes machines impr√©vues le mois dernier qui ont co√ªt√© 40K‚Ç¨, mais le prestataire maintenance actuel est l√† depuis 15 ans",
            "priorites_actuelles": [
                "Livrer la commande Airbus √† temps",
                "Recruter 3 usineurs",
            ],
            "experience_avec_offre_similaire": "Un commercial IoT est pass√© il y a 6 mois, n'a pas convaincu",
            "fournisseur_actuel": "Maintenance Plus SARL, prestataire historique depuis 15 ans",
            "budget_disponible": "Pas de budget pr√©vu, mais pourrait d√©bloquer si ROI d√©montr√©",
        },
    },
    "objections": {
        "objections": [
            {
                "moment": "accroche",
                "verbatim": "C'est √† quel sujet ? J'ai pas beaucoup de temps l√†.",
                "type": "reflexe",
                "difficulte": 3,
                "sous_texte": "Filtrage automatique",
            },
            {
                "moment": "accroche",
                "verbatim": "On a d√©j√† un prestataire qui nous conna√Æt depuis 15 ans et qui fait le job.",
                "type": "sincere",
                "difficulte": 5,
                "sous_texte": "Relation de confiance √©tablie, peur du changement",
            },
            {
                "moment": "decouverte",
                "verbatim": "Ces nouvelles technos, c'est jamais aussi bien qu'annonc√©. Le dernier qui est venu m'a fait perdre une heure.",
                "type": "sincere",
                "difficulte": 4,
                "sous_texte": "√âchaud√© par une mauvaise exp√©rience r√©cente",
            },
            {
                "moment": "argumentation",
                "verbatim": "Rappelez-moi dans 6 mois, l√† c'est pas le moment.",
                "type": "tactique",
                "difficulte": 3,
                "sous_texte": "Veut se d√©barrasser poliment",
            },
            {
                "moment": "argumentation",
                "verbatim": "Combien √ßa co√ªte tout compris ? Parce que l√† on a z√©ro budget pour √ßa.",
                "type": "test",
                "difficulte": 4,
                "sous_texte": "Teste si le vendeur justifie ou questionne",
            },
            {
                "moment": "closing",
                "verbatim": "Envoyez-moi un mail avec une doc, je regarderai quand j'aurai 5 minutes.",
                "type": "tactique",
                "difficulte": 4,
                "sous_texte": "Fa√ßon polie de dire non sans dire non",
            },
        ],
        "objection_finale": {
            "verbatim": "Bon √©coutez, j'ai une r√©union qui commence. Si c'est vraiment int√©ressant, envoyez-moi un truc concret par mail et on verra.",
            "condition_declenchement": "Si le commercial n'a pas cr√©√© d'enjeu apr√®s 5 minutes",
        },
        "pattern_escalade": "Filtrage ‚Üí prestataire actuel ‚Üí scepticisme techno ‚Üí report ‚Üí prix ‚Üí mail poubelle",
    },
    "vendeur": {
        "entreprise": {
            "nom": "TechMaint Solutions",
            "secteur": "Maintenance pr√©dictive industrielle",
            "description": "√âditeur de solutions IoT de surveillance machines en temps r√©el",
        },
        "offre": {
            "nom": "PredictLine",
            "description": "Capteurs IoT + plateforme IA qui d√©tecte les pannes machines 48h avant qu'elles arrivent",
            "proposition_valeur": "R√©duction de 70% des arr√™ts machines non planifi√©s, ROI en 6 mois",
            "prix": "√Ä partir de 800‚Ç¨/mois pour un parc de 10 machines",
            "references": [
                "Fonderies du Rh√¥ne (72 sal.) ‚Äî 3 pannes √©vit√©es en 6 mois",
                "Pr√©cis'Usinage Lyon ‚Äî ROI atteint en 4 mois",
            ],
            "avantages_vs_concurrence": "Seule solution avec IA pr√©dictive certifi√©e pour l'usinage CN, installation en 1 journ√©e sans arr√™t de production",
        },
        "objectif_appel": {
            "type": "rdv_physique",
            "description": "D√©crocher un RDV de 30 minutes sur site pour une d√©monstration live sur une machine",
            "criteres_succes": [
                "Obtenir une date et un cr√©neau",
                "Identifier si le DG est le d√©cideur final",
                "Comprendre le parc machines et les probl√®mes r√©cents",
            ],
        },
        "contexte_appel": {
            "type": "appel_froid",
            "historique": "Premier contact, aucun historique",
            "infos_connues": "PME industrielle Rh√¥ne-Alpes, 85 salari√©s, secteur m√©canique de pr√©cision. Trouv√© via annuaire industriel.",
        },
    },
    "brief_commercial": {
        "titre": "Prospection t√©l√©phonique ‚Äî Maintenance pr√©dictive IoT",
        "vous_etes": "Commercial chez TechMaint Solutions, √©diteur de solutions IoT de maintenance pr√©dictive.",
        "vous_vendez": "PredictLine : capteurs + IA qui d√©tectent les pannes machines 48h √† l'avance. √Ä partir de 800‚Ç¨/mois.",
        "vous_appelez": "Olivier Bertrand, DG de M√©caPress Rh√¥ne-Alpes (85 sal., m√©canique de pr√©cision). Pragmatique, direct, fid√®le √† son prestataire actuel depuis 15 ans.",
        "ce_que_vous_savez": [
            "PME industrielle en croissance, secteur m√©canique de pr√©cision",
            "Trouv√© via annuaire industriel ‚Äî premier contact",
            "Le secteur souffre d'arr√™ts machines impr√©vus co√ªteux",
        ],
        "votre_objectif": "D√©crocher un RDV de 30 min sur site pour une d√©mo live.",
        "vos_atouts": [
            "R√©f√©rence : Fonderies du Rh√¥ne, 3 pannes √©vit√©es en 6 mois",
            "ROI moyen clients : 4-6 mois",
            "Installation en 1 journ√©e, sans arr√™t de production",
        ],
        "duree_estimee": "5-8 minutes",
        "niveau_difficulte": "Interm√©diaire",
    },
}


LANGUAGE_INFO = {
    "fr": {"name": "fran√ßais", "nationality": "fran√ßais(e)", "country": "la France"},
    "en": {"name": "English", "nationality": "British", "country": "the UK"},
    "es": {"name": "espa√±ol", "nationality": "espa√±ol(a)", "country": "Espa√±a"},
    "de": {"name": "Deutsch", "nationality": "deutsch", "country": "Deutschland"},
    "it": {"name": "italiano", "nationality": "italiano/a", "country": "l'Italia"},
}

# --- Greetings pr√©-script√©s (bypass LLM pour la 1√®re r√©plique) ---
GREETINGS = {
    "fr": [
        "Oui all√¥ ?",
        "All√¥, oui ?",
        "{prenom} {nom}, j'√©coute.",
        "Oui bonjour ?",
        "{entreprise}, bonjour.",
    ],
    "en": [
        "Hello?",
        "Yes, hello?",
        "{prenom} {nom} speaking.",
        "Hello, who's calling?",
    ],
    "es": [
        "¬øS√≠, d√≠game?",
        "¬øHola?",
        "{prenom} {nom}, d√≠game.",
    ],
    "de": [
        "Ja, hallo?",
        "{nom}, guten Tag.",
        "Hallo, wer spricht?",
    ],
    "it": [
        "Pronto?",
        "S√¨, pronto?",
        "{prenom} {nom}, mi dica.",
    ],
}


def get_greeting(language: str, persona: dict) -> str:
    """G√©n√®re une phrase d'accueil pr√©-script√©e (bypass LLM, gain ~2-3s)."""
    templates = GREETINGS.get(language, GREETINGS["fr"])
    template = random.choice(templates)
    identite = persona.get("identite", {})
    return template.format(
        prenom=identite.get("prenom", ""),
        nom=identite.get("nom", ""),
        entreprise=identite.get("entreprise", {}).get("nom", ""),
    )


def build_system_prompt(scenario: dict, difficulty: int = 2, language: str = "fr") -> str:
    persona = scenario["persona"]
    objections = scenario["objections"]
    vendeur = scenario.get("vendeur", {})

    # Identit√© prospect
    p = persona["identite"]
    prenom, nom, poste = p["prenom"], p["nom"], p["poste"]
    entreprise = p["entreprise"]["nom"]
    secteur = p["entreprise"].get("secteur", "")

    # Psychologie
    traits = ", ".join(persona["psychologie"]["traits_dominants"])
    style = persona["psychologie"]["style_communication"]

    # Contexte
    ctx = persona["contexte_actuel"]
    situation = ctx["situation_entreprise"]
    priorites = ", ".join(ctx.get("priorites_actuelles", [])[:2]) if ctx.get("priorites_actuelles") else "croissance, rentabilit√©"

    # Motivations et peurs
    motivations = ", ".join(persona["psychologie"].get("motivations_profondes", [])[:2]) if persona["psychologie"].get("motivations_profondes") else "optimiser ses r√©sultats"
    peurs = ", ".join(persona["psychologie"].get("peurs_freins", [])[:2]) if persona["psychologie"].get("peurs_freins") else "perdre du temps, se faire avoir"

    # Tics
    tics = persona["comportement_en_rdv"].get("tics_langage", [])
    tics_str = ", ".join(tics[:4]) if tics else '"Bon...", "√âcoutez...", "Concr√®tement ?"'

    # Objections (max 5)
    obj_list = objections.get("objections", [])[:5]
    objections_str = "\n".join([f'- "{o["verbatim"]}"' for o in obj_list])

    # Contexte vendeur (si disponible)
    vendeur_block = ""
    if vendeur.get("offre"):
        v = vendeur
        vendeur_block = f"""
CE QUE LE VENDEUR VA TE PROPOSER :
Il repr√©sente {v['entreprise']['nom']} et vend {v['offre']['nom']} : {v['offre']['description']}.
Prix : {v['offre'].get('prix', 'non communiqu√©')}.
Son objectif probable : {v['objectif_appel']['description']}.
Ses r√©f√©rences : {', '.join(v['offre'].get('references', []))}.

TU R√âAGIS √Ä CETTE OFFRE SP√âCIFIQUE :
- Si les r√©f√©rences sont dans ton secteur, √ßa t'int√©resse un peu plus
- Si la proposition r√©sout un probl√®me que tu VIS, tu ne peux pas l'ignorer
- Si c'est g√©n√©rique et pas adapt√© √† ton m√©tier, tu coupes court
"""

    # Blocs difficult√©
    DIFF = {
        1: "DIFFICULT√â : D√©butant. Tu es plut√¥t ouvert. Une bonne accroche suffit pour que tu √©coutes. Tu acceptes un RDV facilement si le vendeur le propose correctement.",
        2: "DIFFICULT√â : Interm√©diaire. Tu ne donnes pas ta confiance facilement. Le vendeur doit poser 2-3 bonnes questions avant que tu t'ouvres. Si son argumentation est g√©n√©rique, tu coupes court. Si elle est pertinente, tu peux accepter un RDV.",
        3: "DIFFICULT√â : Expert. Tu es redoutable. Tu interromps, tu challenges tout, tu exiges des preuves. Tu ne l√¢ches rien sans ROI chiffr√© et r√©f√©rences v√©rifiables. Tu raccroches si le vendeur perd ton temps apr√®s 3 minutes."
    }

    # Language block for non-French simulations
    lang_block = ""
    if language != "fr":
        li = LANGUAGE_INFO.get(language, LANGUAGE_INFO["en"])
        lang_block = f"""
LANGUE DE SIMULATION : {li['name']}
Tu es un prospect {li['nationality']} et tu parles UNIQUEMENT en {li['name']}.
Tu ne comprends pas le fran√ßais. Si le commercial te parle en fran√ßais,
tu r√©ponds poliment en {li['name']} que tu ne parles pas fran√ßais.
Adapte tes expressions, ton style et tes r√©f√©rences culturelles au march√© {li['country']}.
"""

    prompt = f"""Tu es {prenom} {nom}, {poste} chez {entreprise} ({secteur}).

PERSONNALIT√â : {traits} | Style : {style}
TICS DE LANGAGE : {tics_str}

CONTEXTE R√âEL :
- Situation : {situation}
- Priorit√©s : {priorites}

TES MOTIVATIONS CACH√âES : {motivations}
TES PEURS : {peurs}

{vendeur_block}

{DIFF.get(difficulty, DIFF[2])}
{lang_block}
COMMENT TU FONCTIONNES :

1. TON √âTAT INTERNE : Ton int√©r√™t commence √† 2/10.
   - Bonne question sur tes VRAIS probl√®mes : +1 √† +2
   - Argument chiffr√© pertinent pour TON secteur : +1 √† +2
   - Pitch g√©n√©rique ou monologue : -1 √† -2
   - R√©f√©rence v√©rifiable dans ton secteur : +2
   - Ton comportement REFL√àTE ce niveau : √† 2 tu es ferm√©, √† 5 tu √©coutes, √† 7+ tu es int√©ress√©

2. RATIONALIT√â : Tu es un {poste}. Tu fais des calculs.
   - Si le vendeur chiffre un gain cr√©dible > ton co√ªt per√ßu, ton int√©r√™t monte
   - Si le vendeur mentionne un probl√®me que tu VIS R√âELLEMENT, tu ne peux pas l'ignorer
   - Si le vendeur dit quelque chose de faux sur ton secteur, tu corriges et ton int√©r√™t baisse

3. M√âMOIRE : Tu te souviens de TOUT dans cet appel.
   - Ne redemande pas une info d√©j√† donn√©e
   - Si le vendeur se contredit, rel√®ve-le
   - Si le vendeur revient sur un point valid√©, ne le rebloque pas

4. CONVERSATION NATURELLE :
   - Phrases courtes, oral fran√ßais naturel. "ouais", "bon", "√©coutez", "d'accord"
   - Tu ne fais JAMAIS de bruits type "hm", "hmm", "mmh"
   - 1-3 phrases max par r√©ponse
   - Tu peux couper si le vendeur monologue >15s
   - Tu vouvoies TOUJOURS, m√™me si le vendeur te tutoie
   - Tu ne sors JAMAIS du personnage
   - IMPORTANT : Tu ne dois JAMAIS utiliser d'abr√©viations dans tes r√©ponses orales. √âcris toujours les mots en entier : "rendez-vous" et non "rdv", "mille euros" et non "k‚Ç¨", "quatorze heures" et non "14h", "chiffre d'affaires" et non "CA". Tu parles, tu n'√©cris pas un SMS.

OBJECTIONS DISPONIBLES (utilise quand c'est PERTINENT, pas dans l'ordre) :
{objections_str}

D√âBUT : Tu as d√©j√† d√©croch√© le t√©l√©phone. Le vendeur va parler. Tu attends sa premi√®re phrase pour r√©pondre.

FIN :
- Int√©r√™t >= 7 et next step propos√© : accepte naturellement
- Int√©r√™t 4-6 et bonne proposition : "envoyez-moi un r√©sum√© par mail"
- Int√©r√™t < 4 apr√®s 3 min : mets fin poliment
"""
    return prompt


# --- Preload VAD + scenarios cache ---
def prewarm(proc: JobProcess):
    proc.userdata["vad"] = silero.VAD.load()
    _ensure_scenarios_db()  # Pre-populate scenario cache in worker process


# --- Entrypoint ---
server = AgentServer()


@server.rtc_session()
async def entrypoint(ctx: JobContext):
    t_entry = time.time()
    logger.info("üéØ Nouvelle session VendMieux")

    await ctx.connect()
    t_connected = time.time()
    logger.info(f"‚è±Ô∏è [latency] connect: {(t_connected - t_entry)*1000:.0f}ms")

    # Charger le sc√©nario et la difficult√© depuis metadata (JSON ou string legacy)
    scenario_id = None
    difficulty = 2
    raw_meta = ctx.room.metadata or ""

    meta_user_id = None
    meta_session_db_id = None
    meta_language = "fr"

    if raw_meta:
        try:
            meta = json.loads(raw_meta)
            scenario_id = meta.get("scenario_id")
            difficulty = int(meta.get("difficulty", 2))
            meta_user_id = meta.get("user_id")
            meta_session_db_id = meta.get("session_db_id")
            meta_language = meta.get("language", "fr")
        except (json.JSONDecodeError, ValueError):
            # Legacy: metadata is just a scenario_id string
            scenario_id = raw_meta if raw_meta else None

    scenario = None
    if scenario_id:
        scenario = load_scenario(scenario_id)
        logger.info(f"üìã Sc√©nario charg√© : {scenario_id}")

    if not scenario:
        scenario = DEFAULT_SCENARIO
        logger.info("üìã Sc√©nario par d√©faut (Olivier Bertrand, industrie)")

    t_scenario = time.time()
    logger.info(f"‚è±Ô∏è [latency] scenario loaded: {(t_scenario - t_entry)*1000:.0f}ms")

    # Fallback difficult√© depuis le sc√©nario si pas dans la metadata
    if difficulty == 2 and not raw_meta:
        difficulty = scenario.get("simulation", {}).get("difficulte", 2)

    # Construire le prompt avec intelligence situationnelle
    system_prompt = build_system_prompt(scenario, difficulty, language=meta_language)
    logger.info(f"üìù System prompt (diff={difficulty}, lang={meta_language}) : {len(system_prompt)} caract√®res")

    # Pr√©parer le greeting pr√©-script√© (bypass LLM)
    greeting = get_greeting(meta_language, scenario["persona"])
    logger.info(f"üëã Greeting pr√©-script√© : \"{greeting}\"")

    # Cr√©er l'agent prospect
    prospect = VendMieuxProspect(
        system_prompt=system_prompt,
        scenario_name=scenario["persona"]["identite"]["prenom"]
        + " "
        + scenario["persona"]["identite"]["nom"],
    )

    t_agent = time.time()
    logger.info(f"‚è±Ô∏è [latency] agent created: {(t_agent - t_entry)*1000:.0f}ms")

    # --- Transcript capture c√¥t√© serveur ---
    transcript_entries = []
    session_start = time.time()

    def on_conversation_item(ev):
        """Capture chaque message (user ou assistant) dans le transcript."""
        item = ev.item
        text = item.text_content
        if not text or not text.strip():
            return
        role = "vendeur" if item.role == "user" else "prospect"
        transcript_entries.append({
            "role": role,
            "text": text.strip(),
            "timestamp": time.time(),
        })
        logger.info(f"üìù [{role}] {text.strip()[:80]}")
        _save_room_history(ctx.room.name, session)

    async def _do_close_evaluation():
        """Coroutine d'√©valuation post-session."""
        duration_s = int(time.time() - session_start)
        nb = len(transcript_entries)
        logger.info(f"üìä Session termin√©e ‚Äî {nb} entr√©es, {duration_s}s")

        if nb < 3:
            logger.info("‚è≠Ô∏è Trop peu d'√©changes pour √©valuer, skip")
            return

        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                payload = {
                    "scenario_id": scenario_id or "__default__",
                    "difficulty": difficulty,
                    "duration_s": duration_s,
                    "transcript": transcript_entries,
                    "user_id": meta_user_id,
                    "session_db_id": meta_session_db_id,
                    "language": meta_language,
                }
                resp = await client.post(
                    "http://127.0.0.1:8000/api/evaluate",
                    json=payload,
                )
                if resp.status_code == 200:
                    score = resp.json().get("score_global", "?")
                    logger.info(f"‚úÖ √âvaluation re√ßue ‚Äî Score: {score}/20")
                else:
                    logger.warning(f"‚ö†Ô∏è √âvaluation √©chou√©e ({resp.status_code}): {resp.text[:200]}")
        except Exception as e:
            logger.error(f"‚ùå Erreur envoi √©valuation: {e}")

    def on_close(ev):
        """Sync callback ‚Äî sauvegarde historique puis lance l'√©valuation."""
        _save_room_history(ctx.room.name, session)
        asyncio.create_task(_do_close_evaluation())

    # Multi-language voice/STT configuration
    VOICE_MAP = {
        "fr": {"voice": "fr-FR-Chirp3-HD-Charon", "language_code": "fr-FR"},
        "en": {"voice": "en-GB-Chirp3-HD-Charon", "language_code": "en-GB"},
        "es": {"voice": "es-ES-Chirp3-HD-Charon", "language_code": "es-ES"},
        "de": {"voice": "de-DE-Chirp3-HD-Charon", "language_code": "de-DE"},
        "it": {"voice": "it-IT-Chirp3-HD-Charon", "language_code": "it-IT"},
    }
    STT_LANG_MAP = {
        "fr": "fr", "en": "en", "es": "es", "de": "de", "it": "it",
    }
    voice_cfg = VOICE_MAP.get(meta_language, VOICE_MAP["fr"])
    stt_lang = STT_LANG_MAP.get(meta_language, "fr")

    # Cr√©er la session avec le pipeline STT ‚Üí LLM ‚Üí TTS
    session = AgentSession(
        vad=silero.VAD.load(),
        stt=deepgram.STT(
            model="nova-3",
            language=stt_lang,
        ),
        llm=anthropic.LLM(
            model="claude-haiku-4-5-20251001",
        ),
        tts=google_tts.TTS(
            voice_name=voice_cfg["voice"],
            language=voice_cfg["language_code"],
            speaking_rate=1.0,
        ),
    )

    # Brancher les callbacks de capture
    session.on("conversation_item_added", on_conversation_item)
    session.on("close", on_close)

    await session.start(
        room=ctx.room,
        agent=prospect,
    )

    t_session_started = time.time()
    logger.info(f"‚è±Ô∏è [latency] session started: {(t_session_started - t_entry)*1000:.0f}ms")

    # V√©rifier si c'est une reconnexion (historique existant pour cette room)
    room_name = ctx.room.name
    prev_history = _pop_room_history(room_name)

    if prev_history is not None:
        from livekit.agents.llm import ChatContext
        restored = ChatContext.from_dict(prev_history)
        session.history.merge(restored)
        nb_restored = len(restored.items)
        logger.info(f"üîÑ Reconnexion ‚Äî {nb_restored} items restaur√©s pour room {room_name}")
        session.say("Excusez-moi, on en √©tait o√π ?", allow_interruptions=True)
    else:
        # Le prospect d√©croche ‚Äî greeting pr√©-script√© (bypass LLM ‚Üí TTS direct, gain ~2-3s)
        session.say(greeting, allow_interruptions=False)

    t_greeting_sent = time.time()
    logger.info(f"‚è±Ô∏è [latency] greeting sent to TTS: {(t_greeting_sent - t_entry)*1000:.0f}ms")
    logger.info(f"‚è±Ô∏è [latency] TOTAL entrypoint‚Üígreeting: {(t_greeting_sent - t_entry)*1000:.0f}ms")


if __name__ == "__main__":
    agents.cli.run_app(server)
